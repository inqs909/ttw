{
  "hash": "c97dded89c2cf8bfa04ed0c41d8752cd",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Tidy Tuesday on Wednesday\"\nsubtitle: \"www.inqs.info/ttw\"\ndate: 02-21-24\ndescription: Third week of Tidy Tuesday on Wednesday at CSUCI! Analyzing the R Consortium ISC Grants.\nformat:\n  revealjs:\n    scrollable: true\n    navigation-mode: vertical\n    controls-layout: bottom-right\n    controls-tutorial: true\n    incremental: false \n    chalkboard:\n      src: chalkboard.json\n      storage: chalkboard_pres\n      theme: whiteboard\n      chalk-width: 4\nengine: knitr\nknitr:\n  opts_chunk: \n    echo: true\n    eval: false\n    comment: \"#>\" \ndraft: false\ncategories:\n  - sp2024\nimage: img/post3.png\nexecute: \n  cache: true\n---\n\n\n# Tidy Tuesday\n\n## Tidy Tuesday\n\nTidy Tuesday is a weekly data visualization challenge from the [R 4 Data Science Online Community](https://github.com/rfordatascience/tidytuesday).\n\n## Week 8\n\nThe R Consortium ISC has been awarding grants since 2016. This week's data is an exploration of past grant recipients.\n\nAre there any keywords that stand out in the titles or summaries of awarded grants? Have the funded amounts changed over time?\n\n\n::: fragment\nMore information about the data can be found on [GitHub](https://github.com/rfordatascience/tidytuesday/blob/master/data/2024/2024-02-20/readme.md) and [Blog Post](https://www.r-consortium.org/blog/2024/02/08/r-consortium-infrastructure-steering-committee-isc-grant-program-accepting-proposals-starting-march-1st).\n:::\n\n::: fragment\nA csv file of the data is [here](https://github.com/rfordatascience/tidytuesday/blob/master/data/2024/2024-02-20/isc_grants.csv).\n:::\n\n::: fragment\nMore on text mining [here](https://www.tidytextmining.com/topicmodeling).\n:::\n\n\n## Loading Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntuesdata <- tidytuesdayR::tt_load(2024, week = 8)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> \tDownloading file 1 of 1: `isc_grants.csv`\n```\n\n\n:::\n\n```{.r .cell-code}\nisc <- tuesdata$isc_grants\n```\n:::\n\n\n## ISC Data\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"datatables html-widget html-fill-item\" id=\"htmlwidget-73f60228a5514b4d3eb7\" style=\"width:100%;height:auto;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-73f60228a5514b4d3eb7\">{\"x\":{\"filter\":\"none\",\"vertical\":false,\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\",\"60\",\"61\",\"62\",\"63\",\"64\",\"65\",\"66\",\"67\",\"68\",\"69\",\"70\",\"71\",\"72\",\"73\",\"74\",\"75\",\"76\",\"77\",\"78\",\"79\",\"80\",\"81\",\"82\",\"83\",\"84\",\"85\"],[2023,2023,2023,2023,2023,2022,2022,2022,2022,2022,2022,2022,2022,2022,2021,2021,2021,2021,2021,2021,2021,2021,2021,2021,2021,2021,2020,2020,2020,2020,2020,2020,2020,2020,2020,2019,2019,2019,2019,2019,2019,2019,2019,2019,2019,2019,2019,2019,2018,2018,2018,2018,2018,2018,2018,2018,2018,2018,2018,2018,2018,2018,2018,2017,2017,2017,2017,2017,2017,2017,2017,2017,2017,2017,2017,2017,2016,2016,2016,2016,2016,2016,2016,2016,2016],[1,1,1,1,1,2,2,2,2,2,1,1,1,1,2,2,2,2,1,1,1,1,1,1,1,1,2,2,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,1,1,1,1,2,2,2,2,2,2,2,2,1,1,1,1,1,1,1,2,2,2,2,1,1,1,1,1,1,1,1,1,2,2,1,1,1,1,1,1,1],[\"The future of DBI (extension 1)\",\"Secure TLS Communications for R\",\"volcalc: Calculate predicted volatility of chemical compounds\",\"autotest: Automated testing of R packages\",\"api2r: An R Package for Auto-Generating R API Clients\",\"D3po: R Package for Easy Interactive D3 Visualization With Shiny\",\"Tooling and Guidance for Translations of Markdown-Based R Content (Quarto, R Markdown)\",\"Online Submission and Review Infrastructure for the R Journal\",\"Upgrading SatRdays Website Template\",\"Building the “Spatial Data Science With R” Educational Materials and Pedagogical Infrastructure\",\"Iterdatasampler: Expanding the lterdatasampler package\",\"Femr: Finite Element Method for Solving PDEs in R\",\"Continuing to Improve R’s Ability to Visualise and Explore Missing Values\",\"Dengue Data Hub\",\"Preparing CRAN for the Retirement of rgdal, rgeos and maptools\",\"R Package for the ICESat-2 Altimeter Data\",\"The Future of DBI\",\"Data Science and Machine Learning Training Workshop Using R Programming Language\",\"Accounting/Auditing Gap-Analysis\",\"Extendr - Rust extensions for R.\",\"Google Earth Engine with R\",\"Improving Translations in R\",\"Minimizing wastage of blood products\",\"R for Engineering Applications\",\"Setting up an R-Girls-Schools Network\",\"deposits: Deposit Research Data Anywhere\",\"Development and maintenance of the Windows build infrastructure (Top level project proposal)\",\"Interactive visualisations in R via R-to-JavaScript-transpilation\",\"Consolidating R-Ladies Global organisational guidance and wisdom\",\"Database interoperability for spatial objects in R\",\"HTTP testing in R Book\",\"MATTER 2.0: larger-than-memory data for R\",\"Spatiotemporal Data and Analytics\",\"The RECON COVID-19 challenge: leveraging the R community to improve COVID-19 analytics resources\",\"sftrack v1.0: Stable API for a broad adoption\",\"An External R Sampling Profiler\",\"CVXR\",\"Flipbooks\",\"R Package Risk Assessment Application\",\"RcppDeepState, a simple way to fuzz test compiled code in R packages\",\"Symbolic mathematics in R with SymPy\",\"Tidy spatial networks in R\",\"d3po: R package for easy interactive D3 visualization with Shiny\",\"webchem: accessing chemical information from the web\",\"Enhancing usability of sample size calculations and power analyses in R with a Task View page and accompanying tutorials\",\"Expanding the ‘metaverse'; an R ecosystem for meta-research\",\"R-global: analysing spatial data globally\",\"sftraj: A central class for tracking and movement data\",\"Catalyzing R-hub adoption through R package developer advocacy\",\"Data-Driven Discovery and Tracking of R Consortium Activities\",\"Editorial assistance for the R Journal\",\"Licensing R - Guidelines and tools\",\"Next-generation text layout in grid and ggplot2\",\"Strengthening of R in support of spatial data infrastructures management : geometa and ows4R R packages\",\"Symbolic Formulae for Linear Mixed Models\",\"serveRless\",\"A unified platform for missing values methods and workflows\",\"Developing Tools and Templates for Teaching Materials\",\"Maintaining DBI\",\"Ongoing infrastructural development for R on Windows and MacOS\",\"PSI application for collaboration to create online R package validation repository\",\"Proposal to Create an R Consortium Working Group Focused on US Census Data\",\"histoRicalg -- Preserving and Transfering Algorithmic Knowledge\",\"An Earth data processing backend for testing and evaluating stars\",\"Future Minimal API: Specification with Backend Conformance Test Suite\",\"Quantities for R\",\"Refactoring and updating the SWIG R module\",\"Adding Linux Binary Builders to CRAN\",\"An infrastructure for building R packages on MacOS Abstract with homebrew\",\"Conference Management System for R Consortium Supported Conferences\",\"Continued Development of the R API for Distributed Computing\",\"Establishing DBI\",\"Forwards Workshops for Women and Girls\",\"Joint profiling of native and R code\",\"School of Data Material Development\",\"stars: Scalable, spatiotemporal tidy arrays for R\",\"Interactive data manipulation in mapview\",\"R Documentation Task Force\",\"A unified framework for Distributed Computing in R\",\"Improving DBI\",\"R Implimentation Optimization Tooling (RIOT) Workshops\",\"RL10N: R Localization Proposal\",\"SatRDays\",\"Simple Features for R\",\"Software Carpentry R Instructor Training\"],[10000,10000,12265,3000,15750,8000,8000,22000,6000,25000,15000,20000,5000,2000,17000,4840,17000,5200,7000,15000,5500,0,11200,3000,5000,16000,46800,9688,4000,6000,16000,35000,10000,23300,5000,8500,9500,6699,16800,34000,10000,9000,4000,6000,13912,20171,10000,10000,46050,5250,50000,6000,25000,20000,6000,10000,14000,10000,26500,62400,4000,4000,772,5000,10000,10000,10000,15000,12000,32000,15000,26500,25000,11000,11200,10000,9100,10000,10000,26500,10000,10000,10000,10000,10000],[\"Kirill Müller\",\"Charlie Gao\",\"Kristina Riemer\",\"Mark Padgham\",\"Jon Harmon\",\"Mauricio \\\"Pacho\\\" Vargas Sepulveda\",\"Maëlle Salmon\",\"Simon Urbanek\",\"Ben Ubah\",\"Orhun Aydin\",\"Julien Brun and Allison Horst\",\"Laura Sangalli\",\"Nicholas Tierney\",\"Thiyanga Talagala\",\"Edzer Pebesma\",\"Lampros Mouselimis\",\"Kirill Müller\",\"Timothy A. Ogunleye\",\"Felix Schildorfer\",\"Andy Thomason\",\"Cesar Luis Aybar Camacho\",\"Michael Chirico\",\"Balasubramanian Narasimhan\",\"Benaiah Chibuokem Ubah\",\"Dr. Razia Ghani\",\"Mark Padgham\",\"Jeroen Ooms\",\"Chun Fung Kwok\",\"Maëlle Salmon\",\"Etienne Racine\",\"Maëlle Salmon\",\"Olga Vitek\",\"Benedikt Gräler\",\"Thibaut Jombart\",\"Mathieu Basille\",\"Aaron Jacobs\",\"David W Kang\",\"Evangeline Reynolds\",\"Andrew Nicholls\",\"Toby Hocking\",\"Mikkel Meyer Andersen\",\"Lucas van der Meer, Robin Lovelace, Andrea Gilardi, Lorena Abad\",\"Mauricio Vargas Sepúlveda\",\"Eric Scott, Tamas Stirling\",\"Richard Webster\",\"Martin Westgate\",\"Edzer Pebesma\",\"Mathieu Basille\",\"Maëlle Salmon\",\"Benaiah Chibuokem Ubah\",\"Dianne Cook\",\"Colin Fay\",\"Claus Wilke\",\"Emmanuel Blondel\",\"Emi Tanaka\",\"Christoph Bodner, Florian Schwendinger, Thomas Laber\",\"Julie Josse\",\"François Michonneau\",\"Kirill Müller\",\"Jeroen Ooms\",\"Lyn Taylor (on behalf of PSI AIMS SIG)\",\"Ari Lamstein\",\"John C Nash\",\"Edzer Pebesma\",\"Henrik Bengtsson\",\"Inaki Ucar\",\"Richard Beare\",\"Dirk Eddelbuettel\",\"Jeroen Ooms\",\"Heather Turner\",\"Michael Lawrence\",\"Kirill Müller\",\"Dianne Cook\",\"Kirill Müller\",\"Heidi Seibold\",\"Edzer Pebesma\",\"Tim Appelhans\",\"Andrew Redd\",\"Michael Lawrence\",\"Kirill Müller\",\"Mark Hornick\",\"Richard Cotton\",\"Stephanie Locke\",\"Edzer Pebesma\",\"Laurent Gatto\"],[\"This proposal mostly focuses on the maintenance and support for {DBI}, the {DBItest} test suite, and the three backends to open-source databases ({RSQLite}, {RMariaDB} and {RPostgres}). Keeping compatibility with the evolving ecosystem (OS, databases, R itself, other packages) is vital for the long-term success of the project.\",\"The project aims to implement secure connections with a TLS layer for encrypted communications in distributed systems used by statisticians and data scientists. The current lack of secure communication tools restricts the use of existing R packages for long-running tasks to trusted local networks, posing security risks in compromised or untrusted environments. The proposed solution addresses this gap by providing encryption and authentication of endpoints, ensuring data security in line with industry standards.\",\"This ISC funded project focuses on the development of the volcalc R package, which automates the estimation of compound volatility based on their chemical structure. The package streamlines the process by downloading chemical structure data, parsing it to identify functional groups, and utilizing the SIMPOL.1 algorithm to predict volatility using functional groups and molecular weight. The compounds are then assigned volatility categories based on a reference environment. This project aims to enhance the package by expanding its compatibility to work with any chemical compound with structural information from various databases. Additionally, improvements in testing and documentation will be implemented to enhance the reliability of the package.\",\"The project aims to develop an R package to automate property-based testing procedures in R, building upon the existing \\\"typetracer\\\" package. The new package will utilize \\\"typetracer\\\" to infer properties of function parameters and systematically mutate or randomize these properties to facilitate automated testing. The package will inherit the GPL-3 license from its predecessor and will be submitted to CRAN for wider dissemination. This initiative aligns with the goal of promoting efficient and reliable testing practices within the R community.\",\"This project aims to develop an R package called api2r, which will automate the creation of R package structures for APIs that adhere to the OpenAPI Specification (OAS). By leveraging the OAS as a foundation, api2r will significantly reduce the time and effort required to build API clients in R. This initiative hopes to have a widespread impact within the R community, benefiting data scientists, researchers, and developers who regularly interact with diverse APIs. To ensure its functionality and effectiveness, the development process will involve generating packages based on at least three authentic OpenAPI specifications.\",\"The D3po: R Package for Easy Interactive D3 Visualization With Shiny project plans to finish a new version of d3po and include maps and other plot types available in highcharts. This project aims to provide out-of-the-box high-quality visualizations with minimum time and coding effort.\\nThe ultimate aim of the project is to produce a package that:\\n\",\"Tooling and Guidance for Translations of Markdown-Based R Content (Quarto, R Markdown) focuses on the achievement of a first version of translated material, both technically (tooling to create an automatically translated document) and linguistically (glossary). With this proposal, the project will aim to share the rOpenSci workflow with others via the creation of an R package including extensive documentation.\",\"The Online Submission and Review Infrastructure for the R Journal ISC-funded project aims to address problems with the current all-manual revision infrastructure for submissions in the R Journal. The project proposes the development and deployment of an online, web-based system that ties into the existing status management infrastructure but allows for reviews and submission management to be performed online. The ISC funds will be used to assist with the development of an online front-end for the management of articles for the R Journal, including submission, checking, and peer-review tracking of articles. The system will leverage the existing rj and rjtools packages which provide the back-end, but will add a web interface to the process from submission to reviews and article management.\",\"The Upgrading SatRdays Website Template project addresses the SatRdays event website templates, which are used by the R community looking to run a SatRday event. The goal of this project is to upgrade the SatRdays website template with a view to make it easy for R community organizers to spin up their own SatRday website without deep knowledge of technologies like Hugo (upon which the current template is based using an R package like blogdown. There will also be documentation of this development with easy-to-follow instructions that are beginner-friendly.\",\"The Building the “Spatial Data Science With R” Educational Materials and Pedagogical Infrastructure project proposes to deliver a set of self-contained online training modules on spatial and spatiotemporal data science with R. The modules will consist of focus-areas pertinent to topics frequently requested by the spatial R community using a large number of packages from CRAN Spatial Task View and Spatiotemporal Task View. The deliverable will provide the R Consortium and community with the materials needed to solicit more lessons from the community while ensuring uniformity across lessons.\",\"Expanding the lterdatasampler Package addresses the need for accessible and relevant datasets in data science education. It aims to provide modern, curated, and approachable environmental data samples from the US Long Term Ecological Research Network (LTER) through the lterdatasampler R package. By offering datasets that save time for instructors, engage students with meaningful data, and foster discussions based on real-world questions.The package serves as a valuable resource for teaching introductory statistics and data science in R. The project seeks funding to expand the package to include data samples from all 28 LTER network sites, with the goal of modernizing course materials with real-world environmental datasets.\",\"Femr: There is a need for implementing finite element methods (FEM) in R to solve partial differential equations (PDEs). PDEs are crucial mathematical tools used for modeling complex phenomena in various scientific and engineering fields. However, the absence of FEM implementations in R necessitates the reliance on external software, discouraging the statistical community from developing methods involving PDEs and hindering the learning of this essential mathematical tool. The goal of the project is to develop the femR package, which will provide a finite element basis for solving second-order linear elliptic PDEs on general two-dimensional spatial domains in R.\\nThis package will complement the existing deSolve package and enable users to employ finite elements instead of finite differences for solving PDEs on more diverse spatial domains. The development process will include providing comprehensive examples and a final vignette to guide users in utilizing the package's functionalities.\",\"The proposal for “Continuing to Improve R’s Ability to Visualise and Explore Missing Values” addresses missing values in data analysis. Missing values are often dropped by default in data analysis in various stages. There is often not even a warning displayed to alert the user of missing values being dropped or discarded. This means values can be dropped without the user knowing, leading to issues such as potential bias, where missing values might be occurring in high numbers in particular groups.\\nThe proposal for the ISC-funded project addressed this problem in four parts:\",\"The Dengue Data Hub project helps addresses data packages related to Dengue. Dengue is a mosquito-borne viral disease that has spread fast throughout the world, primarily in urban and semi-urban regions. The goal of the Dengue Data Hub is to provide the research community with a unified dataset helpful for dengue research and reproducibility of research. The project proposes the creation of an R package for aggregating dengue data from several sources and the ability to share them in tidy format. Based on the proposal, there will also be tutorials and good documentation for using the “Dengue Data Hub” interface. This will motivate epidemiology researchers to utilize R to analyze their data.\",\"The retirement of rgdal, rgeos, and maptools presents a significant impact on the CRAN community, these packages are scheduled for retirement by the end of 2023. In response, a proposal for an ISC Funded project has been put forward to tackle this challenge. Preparing CRAN for the Retirement of rgdal, rgeos and maptools focuses on finding suitable alternatives for the functionalities offered by the retiring packages and providing guidance to package maintainers on necessary adjustments and migration steps. By doing so, it aims to minimize disruption to CRAN packages and existing R scripts, ensuring the overall stability and robustness of the CRAN ecosystem. The retirement process will simplify the maintenance of the \\\"R Spatial stack\\\" and contribute to the long-term health of the CRAN ecosystem.\",\"R Package for the ICESat-2 Altimeter Data aims to create an R package specifically designed for accessing ICESat-2 satellite data through the OpenAltimetry API. Addressing the lack of existing R packages for downloading geospatial data in specific formats, the package will enable R users to download ICESat-2 data, list available data based on a bounding box or named location, create simple feature objects using the sf package, and visualize the output data using popular geospatial R packages such as leaflet or mapview. The proposed ISC-funded project will enhance the capabilities of R users working with geospatial datasets, facilitating data exploration, analysis, and visualization within the R environment for improved geospatial research and applications.\",\"The Future of DBI focuses on the advancements achieved with support from the ISC, including bringing the existing DBI backend, RSQLite, up to specification and implementing two new compliant backends, RMariaDB and RPostgres. This project mostly focuses on the maintenance and support for {DBI}, the {DBItest} test suite, and the three backends to open-source databases ({RSQLite}, {RMariaDB} and {RPostgres}). Ensuring compatibility with evolving elements such as OS, databases, R, and other packages is vital for long-term success. The proposal also includes modules for redesigning the database interface, efficient storage, and arithmetic for big integers, decimals with fixed width and precision, investigating Apache Arrow as an interface, and relational data models with R, with the option to adjust the scope as needed.\",\"We want to conduct training workshops on data science and machine learning with R. Out of nearly 60 countries that form the continent, we carefully selected four countries – one from each of the North, South, West, and East Africa. Nigeria is considered for the West Africa, Kenya is chosen from the East Africa, Sudan from the North Africa, while Zimbabwe is selected from the South African countries. We have 2 volunteers each, who are experts in the field of data science and machine learning with R, from the selected countries. We have also recruited 2 tutors for each country, making a total of 8. These tutors would serve as training assistants to the coordinators. Training materials are to be prepared by the coordinators. Therefore, the coordinators are expected to teach the contents of the training materials.\",\"There are more and more accountants and auditors who want to start using R and dig into data science. They usually have particular tasks on hand that they want to complete, facilitate, or automate. While they often have some basic stats skills and may be some coding basics, understanding the R landscape and relating tasks and processes to locate and use relevant R packages and tutorials is an extreme challenge. While other areas like finance or pharmaceuticals already have extensive infrastructure to support R newcomers (Working Groups, Courses, Task Views, etc.) accounting and auditing do not. This becomes an obstacle for such professionals - which find the “coding” part difficult on their own but doing so without any support or knowing the appropriate package becomes a nightmare.\\nThis is why R Business put together this project with the aim to gauge the landscape of what functionalities are available for Auditors in the R ecosystem and how the existing functionalities can be mapped to routine accounting/auditing tasks. We will complete a systematic survey of the CRAN-ecosystem for accounting/auditing tasks to establish a mapping and identify gaps. The project will contribute to the development of the R Business ISC working group by attracting interested accounting/auditing professionals, industry bodies and R community members. This will then in turn lead to increased use of R/RStudio, development new application domains for data science, and enhancement of the quality of accounting/auditing services.\",\"Rust extension framework for R.\",\"Google Earth Engine (GEE) is the most popular and advanced cloud platform designed for planetary-scale environmental data analysis. Its multi-petabyte data catalog and computation services are just accessed via Python and JavaScript client libraries. In order to facilitate its use within R, six months ago, rgee was released on CRAN using reticulate to wrap the GEE Python API. Although rgee provides a familiar interface and simple integration to other R packages (e.g., sf, raster, dplyr), the lack of tutorials and examples makes it difficult for new users to adopt.\\nThe main goal of this project is to leverage the documentation. For this purpose, three main tasks have been proposed: (1) create a new version of rgee with support for shiny and markdown, (2) create rgeeExtra, which extends the functionalities of rgee, and finally write (3) rgeebook, a reference book with best practices and examples of GEE API usage.\",\"This project will provide a better formalization of translation procedures for R to be more sustainable and more scalable. In the process, it will broaden the inclusivity of R by growing the sub-community of R users comfortable producing translations and extending the reach of the R project to more non-English audiences.\",\"Guan et al. 2017 (Proc Natl Acad Sci U S A 114 (43): 11368–73) used two years worth of data to formulate and solve an optimization problem to predict platelet usage and minimize waste. Two open-source R packages were developed for this purpose:\\n- Platelet Inventory Prediction or pip (https://github.com/bnaras/pip) a package that is the core ML prediction engine that uses a given set of features described in the above publication\\n- Stanford Blood Center Platelet Inventory Prediction or SBCpip (https://github.com/bnaras/SBCpip) that was customized to the data workflow at SHC. SBCpip was meant to be site specific.\\nThere have been a number of requests from sites wishing to deploy the software locally. The current project will generalize the model, generalize it to address more blood products with different shelf lives, provide customizations for local use, and create easily deployable solutions.\",\"R for Engineering Applications is a proposed project with the aim to attract engineers and diversify the use of the R language to the broad engineering domain – electrical, electronic, communications, robotics, etc engineering. The idea is similar to such projects as R in Finance, R in Insurance, BioConductor (R in Bio-informatics), R in Environmental Statistics, etc.\",\"Globally, women, especially from deprived socio-economic and diverse ethnic backgrounds, are under-represented in data science. A major factor is that data science does not feature in the school curriculum which means that teachers are unaware of the enhancements data science can bring to learning and development in and beyond the school. We propose an ongoing project, called R-Girls-School Network (short name R-Girls) to address this and are keen to link up with others.\\nWe are a multi-disciplinary team that includes an educationalist, subject teachers, a data scientist and administrator who will begin to develop and implement a data science curriculum using R in Green Oak Academy – an inner-city school in the UK serving girls from deprived, ethnically diverse backgrounds aged 11-16 years; independently rated as Good with Outstanding for Behaviour and Attitudes.\\nSince GOA follows the UK national curriculum, which is used in 10,000+ schools and 160 countries, our work will have a broad appeal. In due course we will develop ready-to-use bite-sized learning materials (10-15 mins) for teachers of core subjects (maths, statistics, science, geography) to use via RStudio cloud. The lessons will be tested with teachers and pupils and then incorporated into the school timetable across all five-year groups (age 11-16 years), culminating in an R-Data Story project and in due course, an annual R-Girls virtual conference open to any girl and girls' school in the world.\\nR-GS will be supported by a website for showcasing the work of pupils and sharing resources.\",\"Publicly depositing datasets associated with published research is becoming more common, partly due to journals increasingly requiring data sharing, and partly though more general and ongoing cultural changes in relation to data sharing. Yet data sharing is often seen as time consuming, particularly in order to meet the expectations of individual data repositories. While documentation and training can help get users familiar with processes of data sharing, browser-based data and metadata submission workflows can only be so fast, are not easily reproduced, and do not facilitate regular or automated updates of data and metadata. Better programmatic tools can transform data sharing from a mountainous climb into a pit of success.\\nThis project will develop a unified interface to many different research data repositories, and which will function along the lines of dplyr through \\\"verbs\\\" that work identically across many \\\"backend\\\" data repositories. The package will initially provide access to a few of the most common data repositories, yet will implement a modular/plugin system to enable users to contribute their own plugins to extend functionality to other repositories. Users will be able to authenticate, prepare data and metadata, and finally to submit, fetch, and browse data.\",\"As of R 4.0.0 (released April 2020), R for Windows uses a brand new toolchain bundle called rtools40. This version upgrades the mingw-gcc toolchains to version 8.3.0, and introduces a powerful new build system based on the widely used msys2 platform, which makes it easier to maintain R itself, as well as system libraries needed for developing R and R-packages.\\nThe current project seeks to build out this system to improve tooling for building and debugging on Windows, and move towards a scalable build infrastructure, which is transparent, extensible, and fully automated. Thereby we can empower development on Windows, and support further growth of the R ecosystem while relieving work for CRAN and R-core members.\",\"This project aims to make creating flexible interactive visualisation accessible to a wider R community. By implementing an R-to-JavaScript transpiler, i.e. a program that translates R code into JavaScript code, it lets R users develop JavaScript(JS) applications using solely the R syntax. This eliminates the need to pick up an entire new language, makes it easy for R users to learn and experiment with JS technologies and gives direct and full access to all existing JS libraries. The transpiler is distributed as a regular R package, and it can be used standalone or to complement existing packages, including Rmarkdown, shiny and V8.\",\"R-Ladies Global is a successful, growing organization aiming at increasing gender diversity in the R community. R-Ladies Global is a Top-Level Project of the ISC. R-Ladies Global guidance for starting and running a chapter, as well as overseeing chapters around the world, and for the rotating curator account, grew organically. The information is fragmented and exists in different formats: several Markdown and PDF Documents and wiki entries in a GitHub repository. This impedes the optimal finding of resources by those who need them, and also impedes contributions. This project aims to consolidate existing R-Ladies Global guidance into a well-structured and continuously deployed online book, with its source open on GitHub, as ( R ) Markdown documents woven together, and whose maintenance will be an R-Ladies major priority task.\\nThe project will create a web based manuscript containing all the necessary information to understand what the R-Ladies organization is about, its structure and how to contribute to its mission. Information will be collated and organized leveraging the experience of R-Ladies organizers and volunteers that, over the past 4 years, contributed to the establishment and growth of one of the most active and successful communities in the data science realm. This book will be a crucial resource for R-Ladies and other organizations that are looking to consolidate or create their own guidance.\",\"Manipulating spatial data in R sometimes requires interaction with a spatial database: the data doesn't fit in memory, or simply because this is where the data is. The `sf` package already supports the PostGIS spatial database, but this project will extend the compatibility and make it easier to integrate in the `dplyr` workflow (with `dbplyr`). We also want to make it easier to add support for new database backends. We'll create a new `sfdbi` package to centralize the interface between `sf` and databases and remove dependencies in `sf`. If you want to contribute, or if you'd like to suggest a database, make sure to join the `sfdbi` repo.\",\"More and more R packages access resources on the web, and play crucial roles in workflows: data access and updates for CRM reports (Hubspot APIs), for scientific publications (scientific web APIs, Open Science Framework). Like for all other packages, appropriate unit testing can make them more robust. Their unit testing brings special challenges: dependence of tests on a good internet connection, testing in the absence of authentication secrets, etc. Having tests fail due to resources being down or slow, during development or on CRAN, means a time loss for everyone involved (slower development, messages from CRAN). Although many packages accessing remote resources are well tested, there is a lack of resources around best practices for HTTP testing in packages using httr, crul, or curl. The best guidance to date about HTTP testing for R packages to our knowledge is a forum entry that pre-dates the development of relatively new packages for HTTP testing that have now been released on CRAN: vcr and webmockr by Scott Chamberlain, httptest by Neal Richardson, presser by Gábor Csárdi. This project aims at curating a free, central reference for developers of R packages accessing web resources, to help them have a faster and more robust development. We shall develop an useful guidance, in the form of a open-source web-based book.\",\"The project develops the MATTER 2.0 package for computing with larger-than-memory data in R. It extends the functionality of the existing MATTER package to any disk data format and in-memory layout. It also extends MATTER's implementation with ALTREP to provide seamless interoperation with existing code, and various performance improvements critical for rapid prototyping of new statistical methods.\",\"Many data sets are recorded irregular in space and time. Movement of people driving the spread of an disease, or the distribution of current and future cases are per se irregular spatiotemporal data and only two of many examples. Being able to easily visualise, aggregate and model irregular spatiotemporal data will help to better understand and forecast underlying processes. Filling the gap for irregular spatiotemporal data and providing direct interaction with analytical tools will ease the analysis for researchers. We will develop the sftime package to a mature state so that the suite of modern spatial and spatiotemporal data representations in R includes irregular spatiotemporal data. After doing this, we will modify the geostatistical modelling package gstat and the spatial copula modelling package spcopula to support the new data representation classes of sf, stars and sftime.\",\"The RECON COVID-19 challenge aims to bring together the infectious disease modelling, epidemiology and R communities to improve analytics resources for the COVID-19 response via a website which will provide a platform to centralise, curate and update R development tasks relevant to the COVID-19 response. Similar to the Open Street Map Tasking Manager (tasks.hotosm.org), this platform will allow potential contributors to quickly identify outstanding tasks submitted by groups involved in the response to COVID-19 and ensure that developments follow the highest scientific and technical standards.\\nWhile this project is aimed at leveraging R tools for helping to respond to COVID-19, we expect that it will lead to long-lasting developments of partnerships between the R and epidemiological communities, and that the resources developed will become key assets for supporting outbreak responses well beyond this pandemic.\",\"sftrack' is a modern approach for tracking data in R. In response to the large diversity of ad-hoc solutions, in part outdated, we propose a generic and flexible approach that support all stages of movement studies (pre-processing, post-processing and analysis). 'sftrack' provides two central classes for tracking data (points) and movement data (steps), and basic functions to build, handle, summarize and plot them. Version 1.0 of 'sftrack' will be finalized and submitted to CRAN, and will already incorporate converters from/to classes of major existing tracking packages. We will further work with all tracking package developers willing to fully integrate the solution offered by 'sftrack' into their package data flow.\",\"Many R users will be familiar with using the built-in sampling profiler 'Rprof()' to generate data on what their code is doing, and there are several excellent tools to facilitate understanding these samples (or serve as a front-end), including the 'profvis' package. However, the reach of these tools is limited: the profiler is “internal”, in the sense that it must be manually switched on to work, either during interactive work (for example, to profile an individual function), or perhaps by modifying the script to include 'Rprof()' calls before running it again. It cannot be used to understand R code that is already running, a capability that has proven extremely useful for diagnosing and fixing performance issues (or other bugs) in production environments.\\nSeveral existing programming languages have one or more “external” profilers available, which can attach to a running process and read its memory contents to understand what is currently happening. This project aims to build such a tool for R.\",\"Optimization is at the core of statistical estimation and machine learning methodology. There are a number of R packages such as optimx, nloptr, ROI which either implement solvers for a wide variety of problems, or provide an interface to other solvers. The R package CVXR takes a different approach, implementing a Domain Specific Language (Fu, Narasimhan, and Boyd 2019) for formulating and solving convex optimization problems, just as cvxpy does for python. As shown in a number of examples on the CVXR website, the applications range from finance, machine learning, and to theoretical and applied statistics. Using a disciplined convex programming (DCP) approach, CVXR acts as a great tool for both prototyping and developing new methodologies as well as for quick, high-level, formulation and solution of statistical and machine learning problems.\",\"Just as classic flip books allow their readers to observe changes in a scene, coding Flipbooks allow readers to progressively track the changes of code and its output by “flipping” through their digital pages. Flipbooks are useful tools for communicating and teaching because they break down code for incremental, stepwise presentation so that audiences can easily understand each step. Flipbook-building tools automate the deconstruction and reconstruction of coding pipelines which means that building a Flipbook from existing code poses little additional burden to creators. The next stage for this project is to develop the current Flipbook-building tools into a reliable and easy-to-use R package (development is ongoing at https://github.com/EvaMaeRey/flipbookr) and also to provide educational guidance for creating Flipbooks.\",\"The R Validation Hub is an active R Consortium Working Group. It is a cross-industry initiative whose mission is to enable the use of R by the Bio-Pharmaceutical Industry in a regulatory setting, where the output may be used in submissions to regulatory agencies. This project sits within phase 2 of the R Validation Hub's road map. During this phase the group will develop several tools that can be used by those wishing to use R packages within a bio-pharmaceutical regulatory setting. The aim of this specific project is to standardise and simplify the risk assessment of R packages, reducing the burden of package evaluation/testing that would otherwise fall on internal R programming experts. The project will deliver a Shiny application to aid in the assessment and documentation of package risk.\",\"Abstract: Fuzzers are computer programs that send other programs inputs that may fall outside the domain of expected values, thus revealing subtle bugs. DeepState is a testing framework that allows easy testing of C/C++ programs with sophisticated fuzzers, and supports multiple back-ends for testing. DeepState has been used to test critical C++ software, including Google's leveldb. R has some simple random testers, but no coverage-driven fuzzers that learn to produce problematic inputs. We propose to create the R packages RcppDeepState and RcppDeepStateTools which will provide easy-to-use functions for using DeepState with R packages that use C/C++ code via Rcpp. This project will thus provide the first easy-to-use solution for R programmers that want to fuzz test their C/C++ code with existing tools such as AFL, and it will provide a framework for interfacing future coverage-driven fuzzers or symbolic execution tools. We also propose to use these new tools on a wide range of R packages in order to identify bugs in their C/C++ code.\\nOne masters student will be recruited to implement this project during Jan-Dec 2020 at the School of Informatics, Computing, and Cyber Systems at Northern Arizona University. Interested students should apply by emailing a resume/CV along with a cover letter to project supervisors toby.hocking@nau.edu and alex.groce@nau.edu.\",\"R's ability to do symbolic mathematics is largely restricted to finding derivatives. There are many tasks involving symbolic math that are of interest to R users, e.g. inversion of symbolic matrices, limits and solving non-linear equations. Users must resort to other software for such tasks and many R users (especially outside of academia) do not readily have access to such software.\\nThe Python library SymPy is open source, has a stable group of developers and is powerful. As such, R users can just switch to Python and SymPy for symbolic math. However it is often very convenient to stay in the same environment to use familiar syntax and to utilise available libraries (e.g. to generate problems using symbolic math together with the exams package or to first handle symbolic computations and then afterwards move on to a numerical evaluations of the results). We will achieve this by making SymPy functionality available for R users via an R package.\\nCurrently only few R packages for doing symbolic mathematics are available: Two of these are Ryacas and rSymPy. Ryacas is built around Yacas, and although Yacas can solve many problems and is extensible, the community is relatively small and Yacas is not as powerful as SymPy for certain routine tasks (e.g. integration and solving equations). rSymPy on the other hand is based on technology that requires much technical work to install and use.\\nThe website of the project is:\\nhttps://github.com/r-cas/caracas/\\nPlease contribute by testing, writing documentation, opening issues, submitting pull requests or something else!\",\"R is currently lacking a generally applicable, modern and easy-to-use way of handling all kinds of spatial networks. \\\"Tidy spatial networks in R\\\" aims to address this issue by developing and publishing the sfnetworks package. The package, and documentation around it, will provide a bridge between network analysis and spatial analysis communities. For this, an sfnetwork class that will work with both tidygraph and sf frameworks and functions. R-users will be encouraged to contribute and engage with the package development during a hackathon organized next to the eRum 2020.\",\"R already features excellent visualization libraries such as D3 (via the r2d3 package), plotly or highcharter. However, though those enable the creation of great looking visualisations they have very steep learning curves, require understanding of JavaScript or rely on non-free software that might be out of reach for governments and NGOs. Our intention is to solve those problems by releasing d3po. It shall be an intermediate layer between the user and D3 by providing “templates”, enabling high quality interactive visualizations oriented to and designed to be used with Shiny and Rmarkdown, and also proving easy internationalization. Please join us, this needs D3 and R skilled minds!\",\"webchem: accessing chemical information from the web\\nA vast amount of chemical information is freely available on the internet. The data are used by millions of professionals around the world, for purposes like pharmaceutical research, chemical process design, or environmental impact assessment, to name a few. webchem is an R project that aims to help these professionals by providing a single point programmable access to all major chemical databases around the world. The project started in 2016 and currently supports more than 10 databases. If you are interested, join us and help us build the tool that biologists and chemists will absolutely love.\",\"Sample size calculation and power analysis are fundamental for study design, yet they are challenging to do in the R programming language due to limited inter-package documentation. It is difficult to find the required functionality within the sea of open source packages. Indeed, there is no systematic R resource that allows users to search for whether a particular study design and corresponding statistical test has a power analysis implemented in R.\\nOur aims are to improve usability of power analyses performed in R, to facilitate proper design and analysis of data, and promote reproducible research.\\nOur duel approach is to create a Task View page for sample size calculations &amp; power analyses, as well as a series of tutorials to reduce the R users' learning curve. Addressing the usability of sample size calculation / power analyses will benefit a broad spectrum of R users, as this is a vital component for study design, result interpretability and reproducibility.\",\"Evidence synthesis is the process of identifying, collating and summarizing primary scientific research to provide reliable, transparent summaries such as systematic reviews and meta-analyses. Despite their importance for linking research with policy, however, evidence synthesis projects are often time-consuming, expensive, and difficult to update. Open and reproducible workflows would help address these problems, but these workflows are poorly supported by the current package environment, preventing access by new users and hindering uptake of the well-developed suite of statistical tools for meta-analysis in R. The metaverse project will integrate and expand tools to support evidence synthesis and meta-research in R; suggest flexible workflows to complete these projects in a straightforward and open manner; and provide a collector package allowing easy access to these developments for new and experienced users.\",\"Currently, a number of R spatial functions assume that coordinates are two-dimensional, taken from a \\\"flat\\\" space, and may or may not work for geographical (long/lat) coordinates, depicting points on a globe. This project will try to make such functions more robust and helpful for the the case of geographical coordinates. It will reconsider the concept of a bounding box, and build an interface to the S2 geometry library (http://s2geometry.io/), which powers several modern systems that assume geographic coordinates.\",\"Movement defined broadly plays a central and growing role in fields as diverse as transportation, sport, ecology, music, medicine, and data science. Sampling movements results in tracking data, in the form of geographic (x,y,z) and temporal coordinates (t). Despite this common nature, there is a critical lack of standard infrastructure to deal with movement. With a sharp increase of the use of R for movement studies (more than 70 % of movement studies used R in 2018), the Movement community in R is at the same time very dynamic and very fragmented; in 2018 there was 57 packages that process, visualize and analyze tracking data, one third of which worked in isolation, not being linked to any other tracking package. We aim to develop a central trajectory class to support all stages of movement studies (pre-processing, post-processing and analysis).\\nWe propose a sftraj package offering a generic and flexible approach. The only aim of the package will be to present a central class and basic functions to build, handle, summarize and plot movement data. Our project relies on three complementary pillars: a broad involvement of the movement community, a robust conceptual data model, and a sf-based implementation in R. The first stage of the work will specifically involve the Movement community in R. During this stage, we will open contributions of use cases for the package (using GitHub's issue system), which set practical goals for the development of the package. Use cases describe the workflow that is expected from both users' and developers' perspectives, and thus the capabilities that a trajectory package needs to offer. The package specifications and development will aim at addressing all use cases described, to make sure the solution provided is relevant for a wide array of users and package developers.\",\"After the continuing technical progress of R-hub over the last two years, this project aims at catalizing its adoption by R package developers of all levels through developer advocacy. Indeed, R-hub is currently a successful and very valuable project, but it is not documented thoroughly, which hinders its wider adoption by package developers. This project shall answer this concern by three main actions: improving R-hub documentation, making R-hub better known in the community and making the R-hub web site more attractive to, and easier to use by, R developers and users via the ingestion of METACRAN services and the creation of a R-hub blog.\",\"This project proposes an infrastructure that provides a data-driven approach to render the yearly activities of the R Consortium, by deploying web pages for discovering and tracking ISC Funded Projects, RUGS and Marketing activities. These pages are planned to appear like dashboards summarizing activities in interactive tables and charts, presenting several views, trends and insights to what R Consortium has achieved over time. The project hopes that presenting these achievements in a data-driven manner to the R community, the data science community and prospective R Consortium members will promote greater transparency, productivity and community inclusiveness around R Consortium activities.\",\"This project supports the operation of the R Journal. There are two aspects, one is to fund an editorial assistant to send reminders about reviews, and assist with typesetting and copyediting issues. The second part is to explore updating the technical operations of the journal production.\",\"Licensing is a vital part of Open Source. It provides guidelines for interacting with a program, and for making code accessible and reusable (or not). It provides a way to make code open source, in a way one wants to share it, protecting how it will be used and reused. Licensing is also challenging and complex: there are a lot of available licenses, and the choice is influenced by how you import and interact with elements from other packages and/or programs.\\nWith this project, we propose to explore and document the current state of open source licenses in R, and to decipher compatibility and incompatibly elements inside these licenses, to help developers chose the best suited licence for their project.\",\"Text is a key component of any data visualization. We need to label axes and legends, we need to annotate or highlight specific data points, and we need to provide plot titles and captions. The R graphics package ggplot2 provides numerous features to customize the labeling and annotation of plots, but ultimately it is limited by the current capabilities of the underlying graphics libary it uses, grid. Grid can draw simple text strings or mathematical expressions (via plotmath) in different colors, sizes, and fonts. However, it lacks functionality for changing formatting within a string (e.g., draw a single word in italics or in a different color), and it also cannot draw text boxes, where the text is enclosed in a box with defined margins, padding, or background color. This project will support the development of a new package, gridtext, that will alleviate these text formatting limitations. The project will also support efforts to make these new capabilities available from within ggplot2.\",\"The project aims to strengthen the role of R in support of Spatial Data Infrastructures (SDI) management, through major enhancements of the geometa R package which offers tools for reading and writing ISO/OGC geographic metadata, including ISO 19115, 19110, and 19119 through the ISO 19139 XML format. This also extends to the Geographic Markup Language (GML - ISO 19136) used for describing geographic data. The use of geometa in combination with publication tools such as ows4R ( https://cran.r-project.org/package=ows4R ) and geosapi (https://cran.r-project.org/package=geosapi) fosters the use of R software to ease the management and publication of metadata documents and related datasets in web catalogues, and then allows to move forward with a real R implementation of spatial data management plans based on FAIR (Findable, Accessible Interoperable and Reusable) principles.\\nThe workplan includes several activities such as working on the completeness of the ISO 19115 (ISO 19115-1 and 19115-2) data model in geometa, functions to read/write multilingual metadata documents, and an increased metadata validation capability with a validator targeting the EU INSPIRE directive. Finally, functions will be made available to convert between geometa ISO/OGC metadata objects and other known metadata objects such as NetCDF-CF and EML (Ecological Metadata Language) to foster metadata interoperability. By providing these R tools, we seek to facilitate the work of spatial data (GIS) managers, but also data scientists, whatever the thematic domain, whose daily tasks consist in handling data, describing them with metadata and publishing datasets.\",\"Symbolic model formulae define the structural component of a statistical model in an easier and often more accessible terms for practitioners. The earlier instance of symbolic model formulae for linear models was applied in Genstat with further generalisation by Wilkinson and Rogers (1973). Chambers and Hastie (1993) describe the symbolic model formulae implementation for linear models in the S language which remains much the same in the R language (Venables et al. 2018).\\nLinear mixed models (LMMs) are widely used across many disciplines (e.g. ecology, psychology, agriculture, finance etc) due to its flexibility to model complex, correlated structures in the data. While the symbolic formula of linear models generally have a consistent representation and evaluation rule as implemented in stats::formula, this is not the case for LMMs. The inconsistency of symbolic formulae arises mainly in the representation of random effects, with the additional need to specify the variance-covariance structure of the random effects as well as structure of the associated model matrix that governs how the random effects are mapped to (groups of) the observational units. The differences give rise to confusion of equivalent model specification in different R-packages.\\nThe lack of consistency in symbolic formula and model representation across mixed model software motivates the need to formulate a unified symbolic model formulae for LMMs with: (1) extension of the evaluation rules described in Wilkinson and Rogers (1973); and (2) ease of comprehension of the specified model for the user. This symbolic model formulae can be a basis for creating a common API to mixed models with wrappers to popular mixed model R-packages, thereby achieving a similar feat to parsnip R-package (Kuhn 2018) which implements a tidy unified interface to many predictive modelling functions (e.g. random forest, logistic regression, survival models etc).\\nWe would like to find out what are your experiences with fitting linear mixed model in R! Please fill out the survey below to help us understand your problems: https://docs.google.com/forms/d/e/1FAIpQLSeblEoPtDmPS-dH2dmsHjLxLuKl19UY1JdmTrZux-AUSq3N7Q/viewform?usp=sf_link\",\"R is a great language for rapid prototyping and experimentation, but putting an R model in production is still more complex and time-consuming than it needs to be. With the growing popularity of serverless computing frameworks such as AWS Lambda and Azure Functions we see a a huge chance to allow R developers to more easily deploy their code into production. We want to build an R package called 'serverless' to allow R users to easily deploy scripts and custom R packages to AWS Lambda and in a second step to Azure Functions. Our main goal is to build a user-friendly cloud agnostic wrapper that can be extended to include additional cloud providers later on. We want to build on the work already done for deploying R functions to AWS Lambda by Philipp Schirmer and on the work already done by Neal Fultz and Gergely Daróczi on a gRPC client/server for R, which is necessary for Azure Functions. If you like our idea and want to help us, feel free to reach out to us on Github at https://github.com/harlecin/serverless\\nBest,\\nChristoph, Florian and Thomas\",\"The objective is to create a reference platform on the theme of missing data management and to federate contributors. This platform will be the occasion to list the existing packages, the available literature as well as the tutorials that allow to analyze data with missing data. New work on the subject can be easily integrated and we will create examples of analysis workflows with missing data. Anyone who would like to contribute to this exciting project can contact us.\",\"The first-class implementation of literate programming in R is one of the reasons for its success. While the seamless integration of code and text made possible by Sweave, knitr, and rmarkdown was designed for writing reproducible reports and documentation, it has also enabled the creation of teaching materials that combine text, code examples, exercises and solutions. However, while people creating lessons in RMarkdown are familiar with R, they often do not have a background in education or UX design. Therefore, they must not only assemble curriculum, but also find a way to present the content effectively and accessibly to both learners and instructors. As the model of open source development is being adapted to the creation of open educational resources, the difficulty to share materials due to a lack of consistency in their construction hinders the collaborative development of these resources.\\nThis project will develop an R package that will facilitate the development of consistent teaching resources. It will encourage the use of tools and lesson structure that support and improve learning. By providing the technical framework for developing quality teaching materials, we seek to encourage collaborative lesson development by letting authors focus on the content rather than the formatting, while providing a more consistent experience for the learners.\",\"DBI, R's database interface, is a set of methods declared in the DBI R package. Communication with the database is implemented by DBI backends, packages that import DBI and implement its methods. A common interface is helpful for both users and backend implementers.\\nThe \\\"Maintaining DBI\\\" is a follow-up project to two previous projects supported by the R Consortium, and is mostly about providing ongoing maintenance and support for DBI, the DBItest test suite, and the three backends to open-source databases (RSQLite, RMariaDB and RPostgres) that have been implemented as part of the previous projects.\",\"The majority of R users rely on precompiled installers and binary packages for Windows and MacOS that are made available through CRAN. This project seeks to improve and maintain tools for providing such binaries, and relieve some of the dependence on CRAN maintainers and R-core members for doing so. On Windows we will upgrade the Rtools compiler toolchain, and provide up-to-date Windows builds for the many external C/C++ libraries used by CRAN packages. For MacOS we will expand the r-hub \\\"homebrew-cran\\\" tap with formulas that are needed by CRAN packages but not available from upstream homebrew-core. Eventually we want to lay the foundation for a reproducible build system that is low maintenance, automated as much as possible, and which could be used by CRAN and other R package repositories.\",\"The documentation available for R packages currently widely varies. The Statisticians in the Pharmaceutical Industry (PSI) Application and Implementation of Methodologies in Statistics (AIMS) Special Interest Group (SIG) will collaborate with the R-Consortium and representatives from pharmaceutical companies on the setting up of an online repository /web portal, where validation which is of regulatory standard for R packages can be submitted and stored for free use. Companies (or individual R users) would still be liable to make their own assessment on whether the validation is suitable for their own use, however the online repository would serve as a portal for sharing existing regulatory standard validation documentation.\",\"The Proposal to Create an R Consortium Working Group Focused on US Census Data aims to make life easier for R programmers who work with data from the US Census Bureau. It will create a working group where R users working with census data can cooperate under the guidance of the Census Bureau. Additionally, it will publish a guide to working with Census data in R that aims to help R programmers a) select packages that meet their needs and b) navigate the various data sets that the Census Bureau publishes.\",\"Many of the algorithms making up the numerical building-blocks of R were developed several decades ago, particularly in Fortran. Some were translated into C for use by R. Only a modest proportion of R users today are fluent in these languages, and many original authors are no longer active. Yet some of these codes may have bugs or need adjustment for new system capabilities. The histoRicalg project aims to document and test such codes that are still part of R, possibly creating all-R reference codes, hopefully by teaming older and younger workers so knowledge can be shared for the future. Our initial task is to establish a ***Working Group on Algorithms Used in R*** and add material to a website/wiki currently at https://gitlab.com/nashjc/histoRicalg. Interested workers are invited to contact John Nash.\",\"The stars project enables the processing Earth imagery data that is held on servers, without the need to download it to local hard driver. This project will (i) create software to run a back-end, (ii) develop scripts and tutorials that explain how such a data server and processing backend can be set up, and (iii) create an instance of such a backend in the AWS cloud that can be used for testing and evaluation purposes.\",\"The objective of the Future Framework implemented in the future package is to simplify how parallel and distributed processing is conducted in R. This project aims to provide a formal Future API specification and provide a test framework for validating the conformance of existing (e.g. future.batchtools and future.callr) and to-come third-party parallel backends to the Future framework.\",\"The 'units' package has become the reference for quantity calculus in R, with a wide and welcoming response from the R community. Along the same lines, the 'errors' package integrates and automatises error propagation and printing for R vectors. A significant fraction of R users, both practitioners and researchers, use R to analyse measurements, and would benefit from a joint processing of quantity values with errors.\\nThis project not only aims at orchestrating units and errors in a new data type, but will also extend the existing frameworks (compatibility with base R as well as other frameworks such as the tidyverse) and standardise how to import/export data with units and errors.\",\"The Simplified Wrapper and Interface Generator (SWIG) is a tool for automatically generating interface code between interpreters, including R, and a C or C++ library. The R module needs to be updated to support modern developments in R and the rest of SWIG. This project aims to make the R module conform to the recommended SWIG standards and thus ensure that there is support for R in the future. We hope that this project will be the first step in allowing SWIG generated R code using reference classes.\",\"This project proposes to take the creation of binary Linux packages to the next level by providing R-Hub and eventually CRAN with the ability to deliver directly installable binary packages with properly-resolved dependencies. This will allow large-scale automated use of CRAN packages anywhere: laptops, desktops, servers, cluster farms and cloud-based deployments. The project would like to hear from anyone who could possibly host a dedicated server in a rack for long term use.\",\"When installing CRAN packages, Windows and MacOS users often rely on binary packages that contain precompiled source code and any required external C/C++ libraries. By eliminating the need to setup a full compiler environment or manage external libraries this tremendously improves the usability of R on these platforms. Our project will improve the system by adapting the popular homebrew system to facilitate static linking of external libraries\",\"This project will evaluate a number of open source conference management systems to assess their suitability for use with useR! and satRdays. Test versions of these systems will be set up to test their functionality and ease of use for all roles (systems administrator, local organizer, program chair, reviewer, conference participant). A system will be selected and a production system set up, with a view to be ready for useR! 2018 and future satRdays events.\",\"The ISC's Distributed Computing Working Group explores ways of enabling distributed computing in R. One of its outputs, the CRAN package ddR, defines an idiomatic API that abstracts different distributed computing engines, such as DistributedR and potentially Spark and TensorFlow. The goal of the project is to enable R users to interact with familiar data structures and write code that is portable across distributed systems. The working group will use this R Consortium grant to fund an internship to help improve ddR and implement support for one or more additional backends. Please contact Michael Lawrence to apply or request additional information.\",\"Getting data in and out of R is an important part of a statistician's or data scientist's work. If the data reside in a database, this is best done with a backend to DBI, R's native DataBase Interface. The ongoing \\\"Improving DBI\\\" project supports the specification of DBI, both in prose and as an automated test, and also the adaptation of the `RSQLite` package to these specs. This follow-up project aims at implementing modern, fully spec-compliant DBI backends to two major open-source RDBMS, MySQL/MariaDB and PostgreSQL.\",\"The proportion of female package authors and maintainers has remained persistently low, at best at 15%, despite 20 years of the R project's existence. This project will conduct a grassroots effort to increase the participation of women in the R community. One day package development workshops for women engaged in research will be held in Melbourne, Australia and Auckland, New Zealand in 2017, and at locations yet to be determined in the USA and Europe in 2018. Additionally, one day workshops for teenage girls focused on building Shiny apps will be developed to encourage an interest in programming. These will be rolled out in the same locations as the women's workshops. All materials developed will be made available under a Creative Commons share-alike license on the Forwards website (http://forwards.github.io).\",\"R has excellent facilities for profiling R code: the main entry point is the [`Rprof()`](https://www.rdocumentation.org/packages/utils/versions/3.3.2/topics/Rprof) function that starts an execution mode where the R call stack is sampled periodically, optionally at source line level, and written to a file. Profiling results can be analyzed with `summaryRprof()`, or visualized using the `profvis`, `aprof`, or `GUIProfiler` packages. However, the execution time of native code is only available in bulk, without detailed source information. This project aims at bridging this gap with a drop-in replacement to `Rprof()` that records call stacks and memory usage information at both R and native levels, and later commingles them to present a unified view to the user.\",\"School of Data is a network of data literacy practitioners, both organizations and individuals, implementing training and other data literacy activities in their respective countries and regions. Members of School of Data work to empower civil society organizations (CSOs), journalists, civil servants and citizens with the skills they need to use data effectively in their efforts to create better, more equitable and more sustainable societies Our R consortium will develop learning materials about R for journalists, with a focus on making them accessible and relevant to journalists from various countries. As a consequence, our content will use country-relevant examples and will be translated in several languages (English, French, Spanish, German).\",\"Spatiotemporal and raster data often come as dense, two-dimensional arrays while remote sensing and climate model data are often presented as higher dimensional arrays. Data sets of this kind often do not fit in main memory. This project will make it easier to handle such data with R by using dplyr-style, pipe-based workflows, and also consider the case where the data reside remotely, in a cloud environment. Questions and offers to support are welcome through issues at: https://github.com/edzer/stars\",\"The ISC awarded $9,100 to Tim Appelhans, Florian Detsch and Christoph Reudenbach the authors of the Interactive data manipulation in mapview project which aims to extend the capabilities of R for visualizing geospatial data by implementing a two-way data exchange mechanism between R and JavaScript. The central idea is to extend the capabilities of existing tools to enhance the user experience of interactively working with geospatial data by implementing mechanisms for two way data transfer. For example, although htmlwidgets has proven itself to be a powerful framework for enabling interactive, JavaScript based data visualizations, data flow from R to Javascript runs on a one-way street. There is currently no way to pass manipulated data back into the user's R environment. This project aims to first develop a general framework to provide a bridge between htmlwidgets and R to enable a workflow of R -&gt; htmlwidgets -&gt; R and then to use this framework to implement standard interactive spatial data manipulation tools for packages mapview and leaflet. The plan section of the project proposal provides considerable detail on the steps required to achieve the project's goals.\",\"Andrew Redd received $10,000 to lead a new ISC working group, The R Documentation Task Force, which has a mission to design and build the next generation R documentation system. The task force will identify issues with documentation that currently exist, abstract the current Rd system into an R compatible structure, and extend this structure to include new considerations that were not concerns when the Rd system was first implemented. The goal of the project is to create a system that allows for documentation to exist as objects that can be manipulated inside R. This will make the process of creating R documentation much more flexible enabling new capabilities such as porting documentation from other languages or creating inline comments. The new capabilities will add rigor to the documentation process and enable the the system to operate more efficiently than any current methods allow.\",\"Many Big Data platforms expose R-based interfaces that lack standardization and are therefore difficult to learn. This project will develop a common framework to simplify and standardize how users program distributed applications in R, ultimately reducing duplication of effort.\",\"Database access is an important cornerstone of the R ecosystem, but today's specifications – data type transformation, return values, error conditions – remain vague and result in data analysis errors. This project aims to improve database access in R so that porting code is simplified and less prone to error.\",\"RIOT 2016 is a one-day workshop to unite R language developers, identify R language development and tooling opportunities, increase involvement of the R user community and more.\",\"Although the R language is used globally, very few R packages are available in languages other than English. The RL10N project will make it easier for R developers to include translations in their own packages.\",\"“SatRDays” are community-led, regional conferences to support collaboration, networking and innovation within the R community. Initially three events will be hosted, with plans for additional meet-ups as the R user base grows.\",\"Using the “Simple Features” standard supported by the Open Geospatial Consortium and the International Organization for Standardization, this tool will simplify analysis on modern geospatial data.\",\"This two-day in-person training course will introduce the basics of R programming and address the growing demand for training resources for the R language.\"],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,\"https://github.com/kcf-jackson/sketch and https://cran.r-project.org/package=sketch\",\"https://github.com/rladies/starter-kit\",\"https://github.com/r-spatial/sfdbi\",\"https://github.com/ropensci-books/http-testing\",\"https://github.com/kuwisdelu/matter\",\"https://github.com/BenGraeler/STDataAndAnalytics/\",\"https://www.repidemicsconsortium.org/2020-06-09-covid-challenge/\",\"https://github.com/mablab/sftrack\",\"https://github.com/atheriel/xrprof\",\"https://github.com/cvxgrp/CVXR\",\"https://github.com/EvaMaeRey/flipbookr\",\"https://www.pharmar.org/\",\"https://github.com/akhikolla/RcppDeepState\",\"https://github.com/r-cas/caracas/\",\"https://luukvdmeer.github.io/sfnetworks/\",\"https://github.com/pachamaltese/d3po\",\"https://github.com/ropensci/webchem\",\"https://cheori.org/samplesize/\",\"https://rmetaverse.github.io\",\"http://s2geometry.io/\",\"https://github.com/mablab/sftraj\",\"https://blog.r-hub.io\",\"https://benubah.github.io/r-community-explorer/rugs.html\",\"https://rjpilot.netlify.app/\",\"https://github.com/ThinkR-open/isc-proposal-licence/ and https://thinkr-open.github.io/licensing-r/intro.html#getting-a-more-global-idea and https://github.com/ThinkR-open/isc-proposal-licence/blob/master/proposal_licence.md\",\"https://wilkelab.org/gridtext/\",null,null,\"https://github.com/harlecin/serverless\",\"https://cran.r-project.org/web/views/MissingData.html\",\"https://datacarpentry.org/R-ecology-lesson/ and http://swcarpentry.github.io/r-novice-gapminder/\",\"https://dbi.r-dbi.org/\",\"https://github.com/r-hub/homebrew-cran#how-to-use\",\"https://www.pharmar.org/\",\"https://github.com/RConsortium/censusguide\",\"https://gitlab.com/nashjc/histoRicalg\",\"https://r-spatial.github.io/stars/\",\"https://github.com/HenrikBengtsson/\",\"https://github.com/r-quantities/quantities and https://www.r-spatial.org/r/2018/08/31/quantities-final.html\",\"https://github.com/richardbeare/RConsortiumSwig\",null,null,\"https://github.com/satrdays\",\"https://wiki.r-consortium.org/view/Distributed_Computing_Working_Group and https://github.com/vertica/ddR/wiki/Design\",\"https://dbi.r-dbi.org/\",\"https://forwards.github.io/edu/workshops/\",\"https://github.com/krlmlr/profile and https://cran.r-project.org/web/packages/profile/index.html\",null,\"https://cran.r-project.org/web/packages/stars/index.html\",\"https://github.com/environmentalinformatics-marburg/mapview_toolchain and https://cran.r-project.org/package=mapview\",\"https://github.com/RDocTaskForce/documentation\",\"https://github.com/RConsortium/Distributed-Computing-WG\",\"https://dbi.r-dbi.org/\",\"https://riotworkshop.github.io/\",\"https://github.com/RL10N/RL10N and https://libraries.io/github/RL10N\",\"https://github.com/satrdays\",\"https://github.com/r-spatial/sf/\",null]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>year<\\/th>\\n      <th>group<\\/th>\\n      <th>title<\\/th>\\n      <th>funded<\\/th>\\n      <th>proposed_by<\\/th>\\n      <th>summary<\\/th>\\n      <th>website<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"pageLength\":5,\"dom\":\"tp\",\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[1,2,4]},{\"orderable\":false,\"targets\":0},{\"name\":\" \",\"targets\":0},{\"name\":\"year\",\"targets\":1},{\"name\":\"group\",\"targets\":2},{\"name\":\"title\",\"targets\":3},{\"name\":\"funded\",\"targets\":4},{\"name\":\"proposed_by\",\"targets\":5},{\"name\":\"summary\",\"targets\":6},{\"name\":\"website\",\"targets\":7}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false,\"lengthMenu\":[5,10,25,50,100]}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\n\n## Examples\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(tidyverse)\nlibrary(tidytext)\nlibrary(ggwordcloud)\n\nisc_title <- isc |> \n  unnest_tokens(word, title) |> \n  anti_join(stop_words)\n\nisc_title_top <- isc_title |>\n  group_by(group) |> \n  count(word, sort = TRUE) |> filter(n > 1)\n\nisc_title_top |> ggplot(aes(label = word, size = n)) +\n  geom_text_wordcloud() +\n  scale_size_area(max_size = 10) +\n  facet_wrap(~group, labeller =  labeller(group=c('1' = \"Fall\", '2' = \"Spring\"))) +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](week_3_files/figure-revealjs/ex1-1.png){fig-alt='The plot shows two separate word clouds demonstrating the words that most\ncommon words in project titles in both Fall and Spring funding sessions.\nThe most common word in both Fall and Spring was data. Other common words\nin Fall are dbi, api, and development. The most common word in Spring are\npackage, interactive and infrastructure.' width=960}\n:::\n:::\n\n\n## Example\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(ggthemes)\nisc |> ggplot(aes(x=as.factor(year), y = funded)) + \n  geom_boxplot() +\n  geom_jitter(shape = 4) +\n  xlab(\"Year\") + ylab(\"Funded Amount\") + ggtitle(\"\") +\n  theme_wsj()\n```\n\n::: {.cell-output-display}\n![](week_3_files/figure-revealjs/ex2-1.png){fig-alt='The plot shows an overall increase for all items, except in 2021' width=960}\n:::\n:::\n\n\n\n# Installation\n\n## R Programming\n\nR is a statistical programming package that allows you to conduct different types of analysis.\n\n[R](https://www.r-project.org/)\n\n## RStudio\n\nA piece of software that organizes how you conduct statistical analysis in R.\n\n[RStudio](https://posit.co/downloads/)\n\n## Posit Cloud\n\nA web version of RStudio.\n\n[Posit Cloud](https://posit.cloud/login)\n\n## R Packages\n\n-   Tidyverse\n\n-   plotly\n\n-   ggthemes\n\n-   esquisse\n\n-   tidytuesdayR\n\n\n## Load R Package\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(plotly)\nlibrary(ggthemes)\nlibrary(esquisse)\nlibrary(tidytuesdayR)\n```\n:::\n\n\n\n- You must load packages every new R Session\n\n## Visualization Resources\n\n[R Graphics Cookbook](https://r-graphics.org/)\n\n[R Graph Gallery](https://r-graph-gallery.com/)\n\n[R Charts](https://r-charts.com/)\n\n[ggplot2](https://ggplot2.tidyverse.org/)\n\n\n\n# Graphing Examples\n\n## Downloading Data Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nu <- \"https://www.inqs.info/p/plotathon/owenWilsonWows.csv\"\nbasename(u)\ndownload.file(u,\n              file.path(getwd(), \"data\", basename(u)))\n```\n:::\n\n\n## Loading Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmds <- read_csv(\"data/owenWilsonWows.csv\")\n```\n:::\n\n\n\n## Base Plot\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmds |> ggplot(aes(x = total_wows_in_movie)) \n```\n:::\n\n\n## Histogram\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmds |> ggplot(aes(x = total_wows_in_movie)) +\n  geom_histogram()\n```\n:::\n\n\n## Box Plot\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmds |> ggplot(aes(x = total_wows_in_movie)) +\n  geom_boxplot()\n```\n:::\n\n\n## Density Plot\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmds |> ggplot(aes(x = total_wows_in_movie)) +\n  geom_density()\n```\n:::\n\n\n## Box Plot By Category\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmds |> ggplot(aes(x = total_wows_in_movie, y = era)) +\n  geom_boxplot()\n```\n:::\n\n\n## Density Plot By Category\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmds |> ggplot(aes(x = total_wows_in_movie, color = era)) +\n  geom_density()\n```\n:::\n\n\n## Scatter Plot\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmds |> ggplot(aes(x = durationInSeconds, \n                  y = total_wows_in_movie)) +\n  geom_point()\n```\n:::\n\n\n## Scatter Plot by Group\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmds |> ggplot(aes(x = durationInSeconds, \n                  y = total_wows_in_movie, color = era)) +\n  geom_point()\n```\n:::\n\n\n## Add Regression Line\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmds |> ggplot(aes(x = durationInSeconds, \n                  y = total_wows_in_movie)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = F)\n```\n:::\n\n\n## Smooth Line\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmds |> ggplot(aes(x = durationInSeconds, \n                  y = total_wows_in_movie)) +\n  geom_point() +\n  geom_smooth(se = F)\n```\n:::\n\n\n## Regression Lines by Group\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmds |> ggplot(aes(x = durationInSeconds, \n                  y = total_wows_in_movie,\n                  color = era)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = F)\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../site_libs/htmlwidgets-1.6.4/htmlwidgets.js\"></script>\n<link href=\"../site_libs/datatables-css-0.0.0/datatables-crosstalk.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/datatables-binding-0.31/datatables.js\"></script>\n<script src=\"../site_libs/jquery-3.6.0/jquery-3.6.0.min.js\"></script>\n<link href=\"../site_libs/dt-core-1.13.6/css/jquery.dataTables.min.css\" rel=\"stylesheet\" />\n<link href=\"../site_libs/dt-core-1.13.6/css/jquery.dataTables.extra.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/dt-core-1.13.6/js/jquery.dataTables.min.js\"></script>\n<link href=\"../site_libs/crosstalk-1.2.1/css/crosstalk.min.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/crosstalk-1.2.1/js/crosstalk.min.js\"></script>\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}